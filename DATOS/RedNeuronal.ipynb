{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal\n",
    "El código tiene como objetivo entrenar y guardar un modelo de red neuronal para predecir si un punto en el mapa representa un incendio o no. En resumen, el código carga los datos de un archivo CSV, divide los datos en conjuntos de entrenamiento y prueba, normaliza las variables, define la arquitectura de la red neuronal, compila el modelo, entrena la red neuronal y evalúa la precisión de la red. Finalmente, guarda el modelo y los pesos del modelo en dos archivos diferentes. Además, se guarda un escalador para normalizar las variables cuando se hacen predicciones en nuevos datos. También se calcula una matriz de confusión para evaluar la precisión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de entrenamiento\n",
    "dataset = pd.read_csv('./CompleteDataset.csv')\n",
    "X = dataset.iloc[:, :15].values\n",
    "y = dataset.iloc[:, 15].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escalado de variables (normalización)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "# guardar el escalador para usarlo en la predicción de nuevos datos\n",
    "dump(sc_X, open('scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la arquitectura de la red\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(units=16, kernel_initializer=\"uniform\",\n",
    "                             activation=\"sigmoid\", input_dim=14))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar la red\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision del modelo\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir a binario para la matriz de confusión\n",
    "y_train_bin = to_categorical(y_train)\n",
    "y_test_bin = to_categorical(y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_bin = to_categorical(y_pred.round())\n",
    "\n",
    "# matriz de confusión\n",
    "cm = confusion_matrix(\n",
    "    y_test_bin.argmax(axis=1), y_pred_bin.argmax(axis=1))\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "model.save_weights('weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85aece5883f23cf93a903b25fd3f6a5833dab6da9d10cf403dbbc785be5e4181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
