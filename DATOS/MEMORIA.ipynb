{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos meteorológicos\n",
    "Este código procesa los datos meteorológicos de AEMET de cada dia del año y los almacena en un archivo CSV en una carpeta llamada 'ClimaData'. Para hacer esto, carga el archivo CSV que contiene información de incendios en España en 2021 y selecciona las fechas correspondientes a los incendios. Luego, crea un conjunto de procesos paralelos utilizando Multiprocessing para procesar los datos meteorológicos correspondientes a cada fecha en el conjunto de fechas de los incendios.\n",
    "\n",
    "Dentro de la función process_date(), se carga el archivo de datos meteorológicos correspondiente a la fecha proporcionada y se seleccionan las filas que contienen los datos relevantes. Luego, se agregan dos columnas para las coordenadas de latitud y longitud y se carga el archivo con información de la posicion de las estaciones meteorológicas. Se realiza una iteración para encontrar la correspondencia entre el nombre de la estación y los datos meteorológicos. Cuando se encuentra la estación correspondiente, se calculan sus coordenadas a partir de los datos de latitud y longitud que se encuentran en el archivo de información de estaciones. Después de esto, se eliminan las filas que contienen datos faltantes y se renombran las columnas para que tengan nombres más claros. Finalmente, se guarda el conjunto de datos resultante en un archivo CSV en la carpeta 'ClimaData'.\n",
    "\n",
    "### Resultado\n",
    "El resultado de este proceso es un conjunto de datos CSV que contiene información meteorológica de toda España para cada fecha en la que se produjo un incendio en 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_date(date):\n",
    "    \n",
    "    print(f\"Processing date {date}\")\n",
    "\n",
    "    # Se crea el nombre del archivo que contiene los datos meteorológicos de la fecha a procesar\n",
    "    file_name = f'Aemet2021-{date[5:]}.csv'\n",
    "    print(f\"Making {file_name}\")\n",
    "\n",
    "    # Se carga el archivo correspondiente a la fecha a procesar y se seleccionan las filas que contienen los datos\n",
    "    path = f'./ClimaAemet2021/Aemet2021-{date[5:7]}/{file_name}'\n",
    "    dataset_c = pd.read_excel(path).iloc[4:, :]\n",
    "\n",
    "    # Se añaden dos columnas al dataset_c para las coordenadas de latitud y longitud\n",
    "    dataset_c[['latitude', 'longitude']] = np.zeros((len(dataset_c), 2))\n",
    "\n",
    "    # Se carga el archivo con la información de las estaciones y se itera sobre cada fila de dataset_c buscando las correspondencias\n",
    "    # entre el nombre de la estación y los datos meteorológicos. Cuando se encuentra la estación correspondiente, se calculan\n",
    "    # sus coordenadas a partir de los datos de latitud y longitud que se encuentran en el archivo de información de estaciones.\n",
    "    dataset_e = pd.read_excel('./ListadoEstaciones-20190206.xlsx')\n",
    "    for i, row in dataset_c.iterrows():\n",
    "        for j, estacion in dataset_e.iterrows():\n",
    "            if row[0].upper() == estacion[2].upper():\n",
    "                sign = -1 if estacion[5][-1] == 'W' else 1\n",
    "                lat = int(estacion[4][:2]) + int(estacion[4][2:4])/60 + int(estacion[4][4:6])/3600\n",
    "                long = (int(estacion[5][:2]) + int(estacion[5][2:4])/60 + int(estacion[5][4:6])/3600) * sign\n",
    "                dataset_c.loc[i, ['latitude', 'longitude']] = [lat, long]\n",
    "                break\n",
    "\n",
    "    # Se eliminan las filas que contienen datos faltantes y se renombran las columnas para que tengan nombres más claros\n",
    "    dataset_c = dataset_c.dropna()\n",
    "    dataset_c.columns = ['Estación', 'Provincia', 'Temperatura máxima (ºC)', 'Temperatura mínima (ºC)', 'Temperatura media (ºC)', 'Racha (km/h)', \n",
    "    'Velocidad máxima (km/h)', 'Precipitación 00-24h (mm)','Precipitación 00-06h (mm)', 'Precipitación 06-12h (mm)', 'Precipitación 12-18h (mm)' ,'Precipitación 18-24h (mm)', 'Latitude', 'Longitude']\n",
    "\n",
    "    # Se guarda el dataset_c en un archivo CSV en la carpeta 'ClimaData'\n",
    "    dataset_c.to_csv(f'ClimaData/{file_name}', index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Se carga el archivo con la información de los incendios y se seleccionan las columnas necesarias\n",
    "    dataset_i = pd.read_csv('./modis_2021_Spain_incendios.csv').iloc[:, [0, 1, 2, 5]]\n",
    "    with mp.Pool(10) as pool:\n",
    "        pool.map(process_date, dataset_i.iloc[:, 3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTERPOLACION\n",
    "El objetivo de este código es crear un mapa de calor de España de los datos climáticos correspondientes a una fecha determinada. El código lee un archivo CSV que contiene datos de latitud, longitud y la columna seleccionada, filtra los datos para mostrar solo los ubicados dentro de España y define los límites del mapa de calor. Luego, el código crea una cuadrícula de puntos de latitud y longitud, extrae los puntos y valores correspondientes de la columna elegida y los interpola en los puntos de la cuadrícula utilizando el método de interpolación lineal. Finalmente, el código grafica un mapa de calor utilizando los puntos y valores interpolados y ajusta la posición y los detalles de la visualización. La función \"view_heatmap\" permite cambiar la columna seleccionada y la fecha de los datos a visualizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "def view_heatmap(fecha='2021-01-02', colum='Temperatura media (ºC)'):\n",
    "    # Lee los datos climáticos de un archivo CSV correspondiente a la fecha seleccionada.\n",
    "    df = pd.read_csv(f'./ClimaData/Aemet{fecha}.csv')\n",
    "    # Selecciona las columnas de latitud, longitud y la columna elegida.\n",
    "    df = df[['Longitude', 'Latitude', colum]]\n",
    "    # Filtra los datos para que solo muestre los ubicados dentro de España.\n",
    "    df = df.loc[(df['Latitude'] > 30) & (df['Latitude'] < 44) & (df['Longitude'] > -20)]\n",
    "    # Si la columna seleccionada es \"Velocidad máxima (km/h)\", extrae los números de la cadena y los convierte en flotantes.\n",
    "    if colum == 'Velocidad máxima (km/h)':\n",
    "        df[colum] = df[colum].str.extract('(\\d+)', expand=False).astype(float)\n",
    "    else:\n",
    "        df[colum] = df[colum].astype(float)\n",
    "\n",
    "    # Define los límites del mapa de calor.\n",
    "    minx, maxx = df['Longitude'].min(), df['Longitude'].max()\n",
    "    miny, maxy = df['Latitude'].min(), df['Latitude'].max()\n",
    "    # Crea una cuadrícula de 300x300 puntos de latitud y longitud.\n",
    "    grdi_x = np.linspace(minx, maxx, num=300, endpoint=False)\n",
    "    grdi_y = np.linspace(miny, maxy, num=300, endpoint=False)\n",
    "    # Crea una cuadrícula de latitud y longitud 2D.\n",
    "    yg, xg = np.meshgrid(grdi_y, grdi_x, indexing='ij')\n",
    "    # Aplana las cuadrículas para poder usarlas con la función griddata.\n",
    "    x_g, y_g = xg.ravel(), yg.ravel()\n",
    "\n",
    "    # Extrae los puntos y los valores correspondientes de la columna elegida.\n",
    "    points = df[['Longitude', 'Latitude']].values\n",
    "    values = df[colum].values\n",
    "    # Interpola los valores en los puntos de la cuadrícula de latitud y longitud 2D utilizando el método de interpolación lineal.\n",
    "    grid_z0 = griddata(points, values, (x_g, y_g), method='linear')\n",
    "\n",
    "    # Grafica un mapa de calor utilizando los puntos y valores de la cuadrícula interpolada.\n",
    "    plt.scatter(x_g, y_g, s=40, marker='s', c=grid_z0, cmap=plt.cm.hsv)\n",
    "    # Establece las etiquetas de los ejes y la barra de colores.\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.colorbar().set_label(colum)\n",
    "    # Ajusta la posición del mapa de calor.\n",
    "    plt.subplots_adjust(left=0.0, bottom=0.0, right=1, top=1, wspace=0.2, hspace=0.2)\n",
    "    # Establece el color de fondo del mapa de calor en negro.\n",
    "    plt.gca().set_facecolor('xkcd:black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_heatmap(colum = 'Velocidad máxima (km/h)')\n",
    "view_heatmap(colum = 'Precipitación 00-24h (mm)')\n",
    "view_heatmap(colum = 'Temperatura media (ºC)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolación de datos climáticos para cada incendio\n",
    "Este código tiene como objetivo obtener información climática para puntos de incendios en España a partir de un conjunto de datos que incluye la latitud y longitud de los puntos de incendio, así como su fecha de detección. El código carga un conjunto de datos que combina datos de incendios y datos climáticos. Luego, filtra los datos de latitud para excluir aquellos que son menores a 30. Después, agrega nuevas columnas para almacenar los datos climáticos interpolados y guarda el conjunto de datos modificado en un archivo csv.\n",
    "\n",
    "La función interpolate_climate_data() se utiliza para interpolar los datos climáticos para cada punto de incendio en el conjunto de datos. La función carga los datos climáticos correspondientes a la fecha de detección del incendio y los filtra por límites de latitud y longitud. Luego, extrae la latitud, longitud y valores de datos climáticos, los convierte a valores flotantes y luego interpola los datos climáticos para la ubicación del punto de incendio utilizando el método de interpolación lineal. Finalmente, guarda los datos interpolados en la columna correspondiente del conjunto de datos de incendios.\n",
    "\n",
    "El código itera sobre cada punto de datos en el conjunto de datos de incendios y llama a la función interpolate_climate_data() para interpolar los datos climáticos para cada columna de datos climáticos. Por último, guarda el conjunto de datos final con los datos climáticos interpolados en un archivo csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Load dataset of fires with climate data\n",
    "dataset_incendios = pd.read_csv(\"./modis_2021_Spain_incendios_with_clima.csv\")\n",
    "\n",
    "# Filter out data points with latitude less than 30\n",
    "dataset_incendios = dataset_incendios[dataset_incendios['latitude'] > 30]\n",
    "\n",
    "# Add new columns to store interpolated climate data\n",
    "climate_cols = ['Temperatura máxima (ºC)', 'Temperatura mínima (ºC)', 'Temperatura media (ºC)', \n",
    "                'Racha (km/h)', 'Velocidad máxima (km/h)', 'Precipitación 00-24h (mm)', \n",
    "                'Precipitación 00-06h (mm)', 'Precipitación 06-12h (mm)', 'Precipitación 12-18h (mm)', \n",
    "                'Precipitación 18-24h (mm)']\n",
    "for col in climate_cols:\n",
    "    dataset_incendios[col] = np.zeros(len(dataset_incendios))\n",
    "\n",
    "# Save the modified dataset to disk\n",
    "dataset_incendios.to_csv(\"./modis_2021_Spain_incendios_with_clima.csv\", index=False)\n",
    "\n",
    "def interpolate_climate_data(index, column):\n",
    "    # Load climate data for the date of the current fire data point\n",
    "    date = dataset_incendios.iloc[index]['acq_date']\n",
    "    climate_data = pd.read_csv(f'./ClimaData/Aemet{date}.csv')\n",
    "\n",
    "    # Filter climate data by latitude and longitude bounds\n",
    "    climate_data = climate_data[(climate_data['Latitude'] > 30) & (climate_data['Latitude'] < 44) & (climate_data['Longitude'] > -20)]\n",
    "\n",
    "    # Convert climate data values to float\n",
    "    if str(climate_data.iloc[1][column]).find(' ') != -1:\n",
    "        for i in range(len(climate_data)):\n",
    "            climate_data.iloc[i][column] = float(climate_data.iloc[i][column][:climate_data.iloc[i][column].find(' ')])\n",
    "\n",
    "    # Extract latitude, longitude, and climate data values\n",
    "    lat = climate_data['Latitude']\n",
    "    lon = climate_data['Longitude']\n",
    "    values = np.array(climate_data[column], dtype='float64')\n",
    "    lat_arr = np.array(lat, dtype='float64')\n",
    "    lon_arr = np.array(lon, dtype='float64')\n",
    "\n",
    "    # Interpolate climate data value at the location of the current fire data point\n",
    "    est_value = griddata((lat_arr, lon_arr), values, (dataset_incendios.iloc[index]['latitude'], dataset_incendios.iloc[index]['longitude']), method='linear')\n",
    "\n",
    "    # Save the interpolated climate data value to the corresponding column in the fire dataset\n",
    "    dataset_incendios.loc[index, column] = est_value\n",
    "\n",
    "    print(f\"{column} : {est_value}\")\n",
    "\n",
    "# Iterate over each data point in the fire dataset and interpolate climate data for each column\n",
    "for index in range(len(dataset_incendios)):\n",
    "    print(f\"{index} of : {len(dataset_incendios)}\")\n",
    "    for column in climate_cols:\n",
    "        interpolate_climate_data(index, column)\n",
    "\n",
    "# Save the final fire dataset with interpolated climate data to disk\n",
    "dataset_incendios.to_csv(\"./incendios.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos sin incendio en puntos aleatorios\n",
    "Este código tiene como objetivo generar un conjunto de datos de puntos aleatorios que representan ubicaciones geográficas y agregar información meteorológica a estos puntos interpolando valores de un archivo de datos meteorológicos para cada punto.\n",
    "\n",
    "Primero, la función \"getDays\" crea una lista de fechas desde el 1 de enero de 2021 hasta el 31 de diciembre de 2021. Luego, se crea un DataFrame vacío \"datasetRandomPoints\" con columnas que incluyen información geográfica y meteorológica.\n",
    "\n",
    "Luego, se generan 10 puntos aleatorios para cada fecha, y se agregan al DataFrame \"datasetRandomPoints\".\n",
    "\n",
    "Después, se itera sobre el DataFrame y se completa la información meteorológica para cada punto utilizando los datos meteorológicos de un archivo CSV correspondiente a la fecha de cada punto.\n",
    "\n",
    "El código utiliza la función \"griddata\" de la biblioteca \"scipy.interpolate\" para interpolar los valores de temperatura para cada punto en \"datasetRandomPoints\" utilizando los valores de temperatura de los datos meteorológicos del archivo CSV correspondiente a cada punto.\n",
    "\n",
    "Finalmente, el DataFrame \"datasetRandomPoints\" se guarda como un archivo CSV sin índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.interpolate import griddata\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Función para generar una lista de fechas\n",
    "def getDays():\n",
    "    # Definimos el rango de fechas\n",
    "    start_date = date(2021, 1, 1)\n",
    "    end_date = date(2021, 12, 31)\n",
    "    delta = timedelta(days=1)\n",
    "    days = []\n",
    "\n",
    "    # Generamos una lista con todas las fechas entre el rango definido\n",
    "    while start_date <= end_date:\n",
    "        days.append(start_date.strftime(\"%Y-%m-%d\"))\n",
    "        start_date += delta\n",
    "\n",
    "    return days\n",
    "\n",
    "columns = [\n",
    "'Latitude',\n",
    "'Longitude',\n",
    "'acq_date',\n",
    "'Temperatura máxima (ºC)',\n",
    "'Temperatura mínima (ºC)',\n",
    "'Temperatura media (ºC)',\n",
    "'Racha (km/h)',\n",
    "'Velocidad máxima (km/h)',\n",
    "'Precipitación 00-24h (mm)',\n",
    "'Precipitación 00-06h (mm)',\n",
    "'Precipitación 06-12h (mm)',\n",
    "'Precipitación 12-18h (mm)',\n",
    "'Precipitación 18-24h (mm)']\n",
    "\n",
    "datasetRandomPoints = pd.DataFrame(columns=columns)\n",
    "\n",
    "days = getDays()\n",
    "\n",
    "# Generar 10 puntos aleatorios para cada fecha y añadirlos al dataframe\n",
    "for day in days:\n",
    "    for _ in range(10):\n",
    "        lat = random.uniform(37, 43)\n",
    "        lon = random.uniform(-6.5, 0)\n",
    "        datasetRandomPoints = datasetRandomPoints.append({'Latitude': lat, 'Longitude': lon, 'acq_date': day}, ignore_index=True)\n",
    "\n",
    "# Iterar sobre el dataframe y completar los valores de las variables meteorológicas\n",
    "for index in range(len(datasetRandomPoints)):\n",
    "    # Obtener la fecha y la variable meteorológica a completar\n",
    "    day = datasetRandomPoints.iloc[index, 2]\n",
    "    for colum in columns[3:]:\n",
    "        # Leer el archivo CSV correspondiente\n",
    "        df = pd.read_csv(f'./ClimaData/Aemet{day}.csv')\n",
    "        # Obtener el índice de la columna de la variable meteorológica\n",
    "        columnIndex = df.columns.get_loc(colum)\n",
    "        # Seleccionar las columnas de latitud, longitud y la variable meteorológica de interés\n",
    "        df = df.iloc[:,[-1,-2,columnIndex]]\n",
    "        # Filtrar las filas que se encuentran dentro de los límites geográficos\n",
    "        df = df.query('Latitude > 30 and Latitude < 44 and Longitude > -20')\n",
    "        # Si la columna contiene texto, extraer el valor numérico\n",
    "        if str(df.iloc[1,2]).find(' ') != -1:\n",
    "            for _ in range(len(df)):\n",
    "                df.iloc[_,2] = float(df.iloc[_,2][:df.iloc[_,2].find(' ')])\n",
    "        # Separar el dataframe en dos: uno con las columnas de latitud y longitud, y otro con la variable meteorológica de interés\n",
    "        df2 = df.drop([colum], 1)\n",
    "        df3 = df[colum]\n",
    "       # Extraer las columnas 'Latitude' y 'Longitude' del DataFrame de Aemet y almacenarlos en las variables 'lat' y 'lon'\n",
    "        lat = df2['Latitude']\n",
    "        lon = df2['Longitude']\n",
    "\n",
    "        # Extraer los valores de temperatura de la columna especificada en 'colum' del DataFrame de Aemet y almacenarlos en 'values'\n",
    "        values = np.array(df3, dtype='float64')\n",
    "\n",
    "        # Convertir 'lat' y 'lon' en arreglos de tipo float64\n",
    "        arraylat = np.array(lat, dtype='float64')\n",
    "        arraylon = np.array(lon, dtype='float64')\n",
    "\n",
    "        # Interpolar los valores de temperatura en el punto aleatorio del DataFrame de 'datasetRandomPoints' utilizando 'griddata' de la biblioteca 'scipy.interpolate'\n",
    "        est_u = griddata((arraylat, arraylon), values, (datasetRandomPoints.iloc[index,0], datasetRandomPoints.iloc[index,1]), method='linear')\n",
    "\n",
    "        # Obtener el índice de la columna de 'colum' en 'datasetRandomPoints'\n",
    "        columnIndex = datasetRandomPoints.columns.get_loc(colum)\n",
    "\n",
    "        # Almacenar el valor interpolado en la columna correspondiente de 'datasetRandomPoints'\n",
    "        datasetRandomPoints.iloc[index, columnIndex] = est_u\n",
    "\n",
    "# Guardar 'datasetRandomPoints' como un archivo CSV sin el índice\n",
    "datasetRandomPoints.to_csv('datasetRandomPoints.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset combinado de incendios y puntos aleatorios sin incendios para entrenamiento de red neuronal\n",
    "Este código tiene como objetivo combinar dos conjuntos de datos: uno que contiene información sobre incendios y otro que contiene información sobre puntos aleatorios donde no los hubo. El objetivo final es crear un único conjunto de datos que contenga información tanto sobre los incendios como sobre los puntos aleatorios y utilizarlo para entrenar modelos de aprendizaje automático para predecir la ocurrencia de incendios.\n",
    "\n",
    "En el código, se lee y se seleccionan las columnas relevantes de ambos conjuntos de datos, se extraen el mes, día y año de la fecha en ambos conjuntos de datos, se elimina la columna \"acq_date\" en ambos conjuntos de datos y se agrega una columna \"fire\" en cada conjunto de datos para indicar si es un incendio o no. Luego, se concatenan ambos conjuntos de datos en uno solo y se guarda como archivo csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lectura de los datasets\n",
    "datasetRandomPoints = pd.read_csv(\"./datasetRandomPoints.csv\")\n",
    "datasetIncendios = pd.read_csv(\"./incendios.csv\")\n",
    "\n",
    "# Seleccionar columnas relevantes del dataset de incendios\n",
    "datasetIncendios = datasetIncendios.iloc[:, [0, 1, 5, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]]\n",
    "\n",
    "# Extraer mes, día y año de las fechas en ambos datasets\n",
    "datasetRandomPoints['month'] = datasetRandomPoints['acq_date'].apply(lambda x: int(x[5:7]))\n",
    "datasetRandomPoints['day'] = datasetRandomPoints['acq_date'].apply(lambda x: int(x[8:10]))\n",
    "datasetRandomPoints['year'] = datasetRandomPoints['acq_date'].apply(lambda x: int(x[:4]))\n",
    "datasetIncendios['month'] = datasetIncendios['acq_date'].apply(lambda x: int(x[5:7]))\n",
    "datasetIncendios['day'] = datasetIncendios['acq_date'].apply(lambda x: int(x[8:10]))\n",
    "datasetIncendios['year'] = datasetIncendios['acq_date'].apply(lambda x: int(x[:4]))\n",
    "\n",
    "# Eliminar columna acq_date en ambos datasets\n",
    "datasetIncendios = datasetIncendios.drop(['acq_date'], axis=1)\n",
    "datasetRandomPoints = datasetRandomPoints.drop(['acq_date'], axis=1)\n",
    "\n",
    "# Agregar una columna fire a cada dataset para diferenciar incendios de no-incendios\n",
    "datasetIncendios['fire'] = 1\n",
    "datasetRandomPoints['fire'] = 0\n",
    "\n",
    "# Concatenar ambos datasets en uno solo y guardarlo como archivo csv\n",
    "dataset = pd.concat([datasetIncendios, datasetRandomPoints], ignore_index=True)\n",
    "dataset.to_csv('CompleteDataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85aece5883f23cf93a903b25fd3f6a5833dab6da9d10cf403dbbc785be5e4181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
